---
title: 探讨一下一次分表实践
date: 2019/04/16 08:20:00
categories: 
- 架构
tags: 
- db
---

![](https://ws2.sinaimg.cn/large/006tNc79ly1g23egdv1f8j30m80chq6e.jpg)

# 前言

之前不少人问我“能否分享一些分库分表相关的实践”，其实不是我不分享，而是真的经验不多🤣；和大部分人一样都是停留在理论阶段。


不过这次多少有些可以说道了。

先谈谈背景，我们生产数据库随着业务发展量也逐渐起来；好几张单表已经突破**亿级**数据了，并且保持每天 200W 的数据量进行提升。

而我们有些业务需要进行关联查询、或者是报表统计；在这样的背景下大表的问题更加突出（比如一个查询功能需要跑好几分钟）。

> 可能很多人会说：为啥单表都过亿了才想方案解决？其实不是不想，而是由于历史原因加上错误预估了数据增长才导致这个局面。总之原因比较复杂，也不是本次讨论的重点。


# 临时方案

由于需求紧、人手缺的情况下，整个处理的过程分为几个阶段。

第一阶段应该是去年底，当时运维反应 MySQL 所在的主机内存占用很高，整体负载也居高不下，导致整个 MySQL 的吞吐量明显降低（写入、查询数据都明显减慢）。

为此我们找出了数据量最大的几张表，发现大部分数据量在7/8000W 左右，少数的已经突破一亿了。

通过业务层面进行分析发现，这些数据多数都是用户产生的一些**日志型数据**，而且这些数据在业务上并不是强相关的，甚至两三个月前的数据其实已经不需要实时查询了。


因为接近年底，尽可能的不想去动应用，考虑是否可以在运维层面缓解压力；主要的目的就是把单表的数据量降低。


原本是想把两个月之前的数据直接迁移出来放到备份表中，但在准备实施的过程中发现一个大坑。

> 表中没有一个可以排序的索引，导致我们无法快速的筛选出一部分数据！这真的是一个深坑，为后面的一些优化埋下了地雷；即便是加索引也需要花几个小时（具体多久没敢在生产测试）。


如果我们强行按照时间进行筛选，可能查询出 4000W 的数据就得花上好几个小时；这显然是行不通的。


于是我们便想到了一个大胆的想法：这部分数据是否可以直接不要了？

这可能是最有效及最快的方式了，和产品沟通后得知这部分数据真的只是日志型的数据，即便是报表出不来今后补上也是可以的。

于是我们就简单除暴的做了以下事情：

- 修改原有表的表名，比如加上(`_190416bak`)。
- 再新建一张和原有表名称相同的表。


这样新的数据就写到了新表，同时业务上也是使用的这个数据量较小的新表。

随时过程不太优雅，但至少是解决了问题同时也给我们做技术改造预留了时间。

# 分表方案

之前的方案虽说可以缓解压力，但不能根本解决问题。

有些业务必须得查询之前的数据，所以以前那招行不通了，所以正好我们就借助这个机会把表分了。


我相信大部分人虽说没有做过实际做过分表，但也见过猪跑吧。网上一搜各种方案层出不穷。

我认为最重要的一点是要结合实际业务找出需要 sharding 的字段。

## 日期

可能大家都会说用 hash 的方式分配的最均匀，但我认为这是需要历史数据的场景才用这样的方式。


而对于不需要历史数据的场景，比如业务上只查询近三个月的数据。

这类需求完成可以采取时间分表，按照月份进行划分，这样改动简单，同时对历史数据也比较好迁移。

于是我们首先将这类需求的表筛选出来，按照月份进行拆分，只是在查询的时候拼接好表名即可；也比较好理解。

## 哈希

# 业务调整

## 验证

# 上线流程

## 数据迁移



**你的点赞与分享是对我最大的支持**